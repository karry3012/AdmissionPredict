{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Chance of Admit '])\n",
    "y = df['Chance of Admit '].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x_new,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_sc = scaler.fit_transform(x_train)\n",
    "# x_test_sc = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "# model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 0.5704 - val_accuracy: 0.0000e+00 - val_loss: 0.3632\n",
      "Epoch 2/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.4140 - val_accuracy: 0.0000e+00 - val_loss: 0.2841\n",
      "Epoch 3/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.2661 - val_accuracy: 0.0000e+00 - val_loss: 0.2301\n",
      "Epoch 4/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.2029 - val_accuracy: 0.0000e+00 - val_loss: 0.1913\n",
      "Epoch 5/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1678 - val_accuracy: 0.0000e+00 - val_loss: 0.1637\n",
      "Epoch 6/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1416 - val_accuracy: 0.0000e+00 - val_loss: 0.1444\n",
      "Epoch 7/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1411 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
      "Epoch 8/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1124 - val_accuracy: 0.0000e+00 - val_loss: 0.1200\n",
      "Epoch 9/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1046 - val_accuracy: 0.0000e+00 - val_loss: 0.1114\n",
      "Epoch 10/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1019 - val_accuracy: 0.0000e+00 - val_loss: 0.1036\n",
      "Epoch 11/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1032 - val_accuracy: 0.0000e+00 - val_loss: 0.0965\n",
      "Epoch 12/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0895 - val_accuracy: 0.0000e+00 - val_loss: 0.0901\n",
      "Epoch 13/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0873 - val_accuracy: 0.0000e+00 - val_loss: 0.0841\n",
      "Epoch 14/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0779 - val_accuracy: 0.0000e+00 - val_loss: 0.0787\n",
      "Epoch 15/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0668 - val_accuracy: 0.0000e+00 - val_loss: 0.0739\n",
      "Epoch 16/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0699 - val_accuracy: 0.0000e+00 - val_loss: 0.0693\n",
      "Epoch 17/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0632 - val_accuracy: 0.0000e+00 - val_loss: 0.0645\n",
      "Epoch 18/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0556 - val_accuracy: 0.0000e+00 - val_loss: 0.0601\n",
      "Epoch 19/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0607 - val_accuracy: 0.0000e+00 - val_loss: 0.0561\n",
      "Epoch 20/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0492 - val_accuracy: 0.0000e+00 - val_loss: 0.0529\n",
      "Epoch 21/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0514 - val_accuracy: 0.0000e+00 - val_loss: 0.0497\n",
      "Epoch 22/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0448 - val_accuracy: 0.0000e+00 - val_loss: 0.0469\n",
      "Epoch 23/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0410 - val_accuracy: 0.0000e+00 - val_loss: 0.0442\n",
      "Epoch 24/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0415 - val_accuracy: 0.0000e+00 - val_loss: 0.0416\n",
      "Epoch 25/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0423 - val_accuracy: 0.0000e+00 - val_loss: 0.0395\n",
      "Epoch 26/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0362 - val_accuracy: 0.0000e+00 - val_loss: 0.0374\n",
      "Epoch 27/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0372 - val_accuracy: 0.0000e+00 - val_loss: 0.0354\n",
      "Epoch 28/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0344 - val_accuracy: 0.0000e+00 - val_loss: 0.0339\n",
      "Epoch 29/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0315 - val_accuracy: 0.0000e+00 - val_loss: 0.0323\n",
      "Epoch 30/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0347 - val_accuracy: 0.0000e+00 - val_loss: 0.0307\n",
      "Epoch 31/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0317 - val_accuracy: 0.0000e+00 - val_loss: 0.0293\n",
      "Epoch 32/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0278 - val_accuracy: 0.0000e+00 - val_loss: 0.0281\n",
      "Epoch 33/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0289 - val_accuracy: 0.0000e+00 - val_loss: 0.0269\n",
      "Epoch 34/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0300 - val_accuracy: 0.0000e+00 - val_loss: 0.0257\n",
      "Epoch 35/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0268 - val_accuracy: 0.0000e+00 - val_loss: 0.0247\n",
      "Epoch 36/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0248 - val_accuracy: 0.0000e+00 - val_loss: 0.0237\n",
      "Epoch 37/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0208 - val_accuracy: 0.0000e+00 - val_loss: 0.0228\n",
      "Epoch 38/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0214 - val_accuracy: 0.0000e+00 - val_loss: 0.0220\n",
      "Epoch 39/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0219 - val_accuracy: 0.0000e+00 - val_loss: 0.0212\n",
      "Epoch 40/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0201 - val_accuracy: 0.0000e+00 - val_loss: 0.0204\n",
      "Epoch 41/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0209 - val_accuracy: 0.0000e+00 - val_loss: 0.0196\n",
      "Epoch 42/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0198 - val_accuracy: 0.0000e+00 - val_loss: 0.0190\n",
      "Epoch 43/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0177 - val_accuracy: 0.0000e+00 - val_loss: 0.0184\n",
      "Epoch 44/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0170 - val_accuracy: 0.0000e+00 - val_loss: 0.0177\n",
      "Epoch 45/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.0172\n",
      "Epoch 46/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0164 - val_accuracy: 0.0000e+00 - val_loss: 0.0167\n",
      "Epoch 47/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0149 - val_accuracy: 0.0000e+00 - val_loss: 0.0162\n",
      "Epoch 48/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0146 - val_accuracy: 0.0000e+00 - val_loss: 0.0156\n",
      "Epoch 49/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0153 - val_accuracy: 0.0000e+00 - val_loss: 0.0151\n",
      "Epoch 50/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0150 - val_accuracy: 0.0000e+00 - val_loss: 0.0147\n",
      "Epoch 51/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0128 - val_accuracy: 0.0000e+00 - val_loss: 0.0144\n",
      "Epoch 52/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0144 - val_accuracy: 0.0000e+00 - val_loss: 0.0139\n",
      "Epoch 53/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0136 - val_accuracy: 0.0000e+00 - val_loss: 0.0135\n",
      "Epoch 54/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0120 - val_accuracy: 0.0000e+00 - val_loss: 0.0132\n",
      "Epoch 55/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0124 - val_accuracy: 0.0000e+00 - val_loss: 0.0129\n",
      "Epoch 56/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0120 - val_accuracy: 0.0000e+00 - val_loss: 0.0127\n",
      "Epoch 57/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.0121 - val_accuracy: 0.0000e+00 - val_loss: 0.0124\n",
      "Epoch 58/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 0.0121\n",
      "Epoch 59/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.0115 - val_accuracy: 0.0000e+00 - val_loss: 0.0119\n",
      "Epoch 60/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0099 - val_accuracy: 0.0000e+00 - val_loss: 0.0117\n",
      "Epoch 61/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0101 - val_accuracy: 0.0000e+00 - val_loss: 0.0114\n",
      "Epoch 62/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0095 - val_accuracy: 0.0000e+00 - val_loss: 0.0112\n",
      "Epoch 63/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0096 - val_accuracy: 0.0000e+00 - val_loss: 0.0110\n",
      "Epoch 64/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0084 - val_accuracy: 0.0000e+00 - val_loss: 0.0108\n",
      "Epoch 65/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0092 - val_accuracy: 0.0000e+00 - val_loss: 0.0106\n",
      "Epoch 66/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0085 - val_accuracy: 0.0000e+00 - val_loss: 0.0104\n",
      "Epoch 67/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0085 - val_accuracy: 0.0000e+00 - val_loss: 0.0103\n",
      "Epoch 68/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0107 - val_accuracy: 0.0000e+00 - val_loss: 0.0100\n",
      "Epoch 69/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 0.0099\n",
      "Epoch 70/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 0.0097\n",
      "Epoch 71/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 0.0096\n",
      "Epoch 72/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 0.0095\n",
      "Epoch 73/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0085 - val_accuracy: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 74/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0082 - val_accuracy: 0.0000e+00 - val_loss: 0.0092\n",
      "Epoch 75/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0075 - val_accuracy: 0.0000e+00 - val_loss: 0.0091\n",
      "Epoch 76/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0078 - val_accuracy: 0.0000e+00 - val_loss: 0.0090\n",
      "Epoch 77/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 78/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0074 - val_accuracy: 0.0000e+00 - val_loss: 0.0088\n",
      "Epoch 79/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0087\n",
      "Epoch 80/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 81/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0069 - val_accuracy: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 82/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0085\n",
      "Epoch 83/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0084\n",
      "Epoch 84/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 0.0084\n",
      "Epoch 85/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 86/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 87/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 88/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0080\n",
      "Epoch 89/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0080\n",
      "Epoch 90/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0076 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 91/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0063 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 92/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 93/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0078\n",
      "Epoch 94/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 95/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 96/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0076\n",
      "Epoch 97/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 98/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 99/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 100/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 101/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 102/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0056 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 103/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 104/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 105/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 106/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 107/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 108/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 109/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 110/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 111/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 112/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 113/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 114/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 115/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 116/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 117/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 118/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 119/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 120/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 121/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 122/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 123/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 124/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 125/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0056 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 126/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 127/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 128/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 129/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 130/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 131/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 132/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0042 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 133/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 134/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 135/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 136/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 137/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 138/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 139/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0042 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 140/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 141/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0044 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 142/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0044 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 143/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 144/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0045 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 145/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 146/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 147/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 148/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0041 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 149/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 150/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 151/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 152/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 153/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 154/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 155/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.0041 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 156/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0042 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 157/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 158/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 159/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0044 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 160/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n",
      "Epoch 161/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n",
      "Epoch 162/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0041 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 163/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 164/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n",
      "Epoch 165/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0045 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n",
      "Epoch 166/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0043 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=1000,validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62765641, 0.42725722, 0.79882862, 1.09386422, 0.61012728,\n",
       "       0.92528814, 0.90911166])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6989416196664853"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3053edf50>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x30542c590>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.1111 - mae: 0.9700 - val_loss: 1.0929 - val_mae: 0.9572\n",
      "Epoch 2/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9160 - mae: 0.8717 - val_loss: 0.8850 - val_mae: 0.8496\n",
      "Epoch 3/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6860 - mae: 0.7473 - val_loss: 0.7139 - val_mae: 0.7519\n",
      "Epoch 4/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5905 - mae: 0.6944 - val_loss: 0.5752 - val_mae: 0.6622\n",
      "Epoch 5/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4602 - mae: 0.5996 - val_loss: 0.4691 - val_mae: 0.5967\n",
      "Epoch 6/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3731 - mae: 0.5341 - val_loss: 0.3981 - val_mae: 0.5408\n",
      "Epoch 7/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2882 - mae: 0.4600 - val_loss: 0.3481 - val_mae: 0.4907\n",
      "Epoch 8/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2492 - mae: 0.4193 - val_loss: 0.3121 - val_mae: 0.4538\n",
      "Epoch 9/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2280 - mae: 0.3826 - val_loss: 0.2822 - val_mae: 0.4199\n",
      "Epoch 10/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1872 - mae: 0.3479 - val_loss: 0.2555 - val_mae: 0.3940\n",
      "Epoch 11/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1727 - mae: 0.3350 - val_loss: 0.2329 - val_mae: 0.3742\n",
      "Epoch 12/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1491 - mae: 0.3172 - val_loss: 0.2132 - val_mae: 0.3569\n",
      "Epoch 13/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1496 - mae: 0.3140 - val_loss: 0.1962 - val_mae: 0.3425\n",
      "Epoch 14/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1416 - mae: 0.3107 - val_loss: 0.1819 - val_mae: 0.3295\n",
      "Epoch 15/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1493 - mae: 0.3119 - val_loss: 0.1686 - val_mae: 0.3167\n",
      "Epoch 16/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1261 - mae: 0.2891 - val_loss: 0.1575 - val_mae: 0.3055\n",
      "Epoch 17/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1236 - mae: 0.2800 - val_loss: 0.1458 - val_mae: 0.2931\n",
      "Epoch 18/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1086 - mae: 0.2671 - val_loss: 0.1364 - val_mae: 0.2826\n",
      "Epoch 19/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1114 - mae: 0.2712 - val_loss: 0.1266 - val_mae: 0.2715\n",
      "Epoch 20/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0969 - mae: 0.2535 - val_loss: 0.1177 - val_mae: 0.2608\n",
      "Epoch 21/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0718 - mae: 0.2150 - val_loss: 0.1102 - val_mae: 0.2515\n",
      "Epoch 22/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0887 - mae: 0.2378 - val_loss: 0.1015 - val_mae: 0.2408\n",
      "Epoch 23/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0732 - mae: 0.2231 - val_loss: 0.0943 - val_mae: 0.2317\n",
      "Epoch 24/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0744 - mae: 0.2258 - val_loss: 0.0872 - val_mae: 0.2226\n",
      "Epoch 25/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0754 - mae: 0.2207 - val_loss: 0.0808 - val_mae: 0.2146\n",
      "Epoch 26/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0685 - mae: 0.2106 - val_loss: 0.0752 - val_mae: 0.2066\n",
      "Epoch 27/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0561 - mae: 0.1926 - val_loss: 0.0698 - val_mae: 0.1986\n",
      "Epoch 28/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0677 - mae: 0.2082 - val_loss: 0.0643 - val_mae: 0.1903\n",
      "Epoch 29/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0677 - mae: 0.2015 - val_loss: 0.0597 - val_mae: 0.1827\n",
      "Epoch 30/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0576 - mae: 0.1917 - val_loss: 0.0558 - val_mae: 0.1755\n",
      "Epoch 31/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0517 - mae: 0.1826 - val_loss: 0.0526 - val_mae: 0.1691\n",
      "Epoch 32/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0448 - mae: 0.1701 - val_loss: 0.0489 - val_mae: 0.1626\n",
      "Epoch 33/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0463 - mae: 0.1694 - val_loss: 0.0458 - val_mae: 0.1564\n",
      "Epoch 34/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0428 - mae: 0.1658 - val_loss: 0.0433 - val_mae: 0.1515\n",
      "Epoch 35/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0425 - mae: 0.1590 - val_loss: 0.0403 - val_mae: 0.1461\n",
      "Epoch 36/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0356 - mae: 0.1517 - val_loss: 0.0383 - val_mae: 0.1420\n",
      "Epoch 37/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0384 - mae: 0.1532 - val_loss: 0.0361 - val_mae: 0.1377\n",
      "Epoch 38/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0319 - mae: 0.1444 - val_loss: 0.0344 - val_mae: 0.1344\n",
      "Epoch 39/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1486 - val_loss: 0.0326 - val_mae: 0.1312\n",
      "Epoch 40/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1510 - val_loss: 0.0312 - val_mae: 0.1283\n",
      "Epoch 41/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0299 - mae: 0.1381 - val_loss: 0.0299 - val_mae: 0.1256\n",
      "Epoch 42/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0326 - mae: 0.1426 - val_loss: 0.0287 - val_mae: 0.1231\n",
      "Epoch 43/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0269 - mae: 0.1300 - val_loss: 0.0276 - val_mae: 0.1208\n",
      "Epoch 44/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mae: 0.1367 - val_loss: 0.0265 - val_mae: 0.1183\n",
      "Epoch 45/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - mae: 0.1268 - val_loss: 0.0253 - val_mae: 0.1161\n",
      "Epoch 46/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0262 - mae: 0.1274 - val_loss: 0.0246 - val_mae: 0.1138\n",
      "Epoch 47/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0251 - mae: 0.1265 - val_loss: 0.0237 - val_mae: 0.1116\n",
      "Epoch 48/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0261 - mae: 0.1307 - val_loss: 0.0228 - val_mae: 0.1096\n",
      "Epoch 49/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.1189 - val_loss: 0.0221 - val_mae: 0.1078\n",
      "Epoch 50/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0232 - mae: 0.1241 - val_loss: 0.0213 - val_mae: 0.1063\n",
      "Epoch 51/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0206 - val_mae: 0.1046\n",
      "Epoch 52/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0253 - mae: 0.1250 - val_loss: 0.0198 - val_mae: 0.1028\n",
      "Epoch 53/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - mae: 0.1163 - val_loss: 0.0192 - val_mae: 0.1012\n",
      "Epoch 54/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0198 - mae: 0.1117 - val_loss: 0.0185 - val_mae: 0.0997\n",
      "Epoch 55/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0204 - mae: 0.1132 - val_loss: 0.0179 - val_mae: 0.0983\n",
      "Epoch 56/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0210 - mae: 0.1173 - val_loss: 0.0175 - val_mae: 0.0969\n",
      "Epoch 57/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0189 - mae: 0.1133 - val_loss: 0.0170 - val_mae: 0.0958\n",
      "Epoch 58/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0201 - mae: 0.1109 - val_loss: 0.0165 - val_mae: 0.0946\n",
      "Epoch 59/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.1029 - val_loss: 0.0160 - val_mae: 0.0933\n",
      "Epoch 60/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.1105 - val_loss: 0.0154 - val_mae: 0.0917\n",
      "Epoch 61/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.1078 - val_loss: 0.0150 - val_mae: 0.0906\n",
      "Epoch 62/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.1050 - val_loss: 0.0146 - val_mae: 0.0894\n",
      "Epoch 63/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.1091 - val_loss: 0.0143 - val_mae: 0.0882\n",
      "Epoch 64/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.1004 - val_loss: 0.0138 - val_mae: 0.0869\n",
      "Epoch 65/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.1001 - val_loss: 0.0135 - val_mae: 0.0859\n",
      "Epoch 66/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0982 - val_loss: 0.0133 - val_mae: 0.0850\n",
      "Epoch 67/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.1014 - val_loss: 0.0129 - val_mae: 0.0840\n",
      "Epoch 68/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0936 - val_loss: 0.0127 - val_mae: 0.0831\n",
      "Epoch 69/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0975 - val_loss: 0.0123 - val_mae: 0.0820\n",
      "Epoch 70/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0954 - val_loss: 0.0120 - val_mae: 0.0807\n",
      "Epoch 71/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0963 - val_loss: 0.0117 - val_mae: 0.0799\n",
      "Epoch 72/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0139 - mae: 0.0939 - val_loss: 0.0115 - val_mae: 0.0790\n",
      "Epoch 73/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0926 - val_loss: 0.0113 - val_mae: 0.0779\n",
      "Epoch 74/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0911 - val_loss: 0.0110 - val_mae: 0.0770\n",
      "Epoch 75/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0926 - val_loss: 0.0108 - val_mae: 0.0761\n",
      "Epoch 76/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0850 - val_loss: 0.0106 - val_mae: 0.0752\n",
      "Epoch 77/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0899 - val_loss: 0.0102 - val_mae: 0.0738\n",
      "Epoch 78/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0836 - val_loss: 0.0101 - val_mae: 0.0731\n",
      "Epoch 79/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0853 - val_loss: 0.0099 - val_mae: 0.0721\n",
      "Epoch 80/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0786 - val_loss: 0.0097 - val_mae: 0.0714\n",
      "Epoch 81/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0823 - val_loss: 0.0097 - val_mae: 0.0710\n",
      "Epoch 82/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0826 - val_loss: 0.0095 - val_mae: 0.0702\n",
      "Epoch 83/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0855 - val_loss: 0.0093 - val_mae: 0.0693\n",
      "Epoch 84/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0823 - val_loss: 0.0091 - val_mae: 0.0684\n",
      "Epoch 85/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0090 - val_mae: 0.0681\n",
      "Epoch 86/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0826 - val_loss: 0.0089 - val_mae: 0.0674\n",
      "Epoch 87/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - mae: 0.0792 - val_loss: 0.0088 - val_mae: 0.0674\n",
      "Epoch 88/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0800 - val_loss: 0.0086 - val_mae: 0.0659\n",
      "Epoch 89/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - mae: 0.0805 - val_loss: 0.0084 - val_mae: 0.0652\n",
      "Epoch 90/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0767 - val_loss: 0.0083 - val_mae: 0.0644\n",
      "Epoch 91/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0743 - val_loss: 0.0083 - val_mae: 0.0658\n",
      "Epoch 92/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0724 - val_loss: 0.0083 - val_mae: 0.0653\n",
      "Epoch 93/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0081 - val_mae: 0.0646\n",
      "Epoch 94/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0733 - val_loss: 0.0080 - val_mae: 0.0635\n",
      "Epoch 95/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - mae: 0.0743 - val_loss: 0.0078 - val_mae: 0.0631\n",
      "Epoch 96/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0715 - val_loss: 0.0077 - val_mae: 0.0623\n",
      "Epoch 97/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mae: 0.0661 - val_loss: 0.0077 - val_mae: 0.0629\n",
      "Epoch 98/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0747 - val_loss: 0.0077 - val_mae: 0.0637\n",
      "Epoch 99/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0724 - val_loss: 0.0076 - val_mae: 0.0637\n",
      "Epoch 100/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - mae: 0.0665 - val_loss: 0.0074 - val_mae: 0.0621\n",
      "Epoch 101/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - mae: 0.0701 - val_loss: 0.0074 - val_mae: 0.0620\n",
      "Epoch 102/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0702 - val_loss: 0.0073 - val_mae: 0.0616\n",
      "Epoch 103/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0655 - val_loss: 0.0073 - val_mae: 0.0621\n",
      "Epoch 104/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - mae: 0.0670 - val_loss: 0.0072 - val_mae: 0.0620\n",
      "Epoch 105/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - mae: 0.0663 - val_loss: 0.0071 - val_mae: 0.0612\n",
      "Epoch 106/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mae: 0.0654 - val_loss: 0.0071 - val_mae: 0.0613\n",
      "Epoch 107/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0658 - val_loss: 0.0070 - val_mae: 0.0611\n",
      "Epoch 108/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - mae: 0.0695 - val_loss: 0.0069 - val_mae: 0.0611\n",
      "Epoch 109/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - mae: 0.0682 - val_loss: 0.0068 - val_mae: 0.0601\n",
      "Epoch 110/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0660 - val_loss: 0.0068 - val_mae: 0.0603\n",
      "Epoch 111/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - mae: 0.0649 - val_loss: 0.0068 - val_mae: 0.0605\n",
      "Epoch 112/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0648 - val_loss: 0.0067 - val_mae: 0.0598\n",
      "Epoch 113/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0617 - val_loss: 0.0066 - val_mae: 0.0591\n",
      "Epoch 114/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - mae: 0.0651 - val_loss: 0.0065 - val_mae: 0.0595\n",
      "Epoch 115/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0066 - val_mae: 0.0598\n",
      "Epoch 116/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0653 - val_loss: 0.0066 - val_mae: 0.0600\n",
      "Epoch 117/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - mae: 0.0596 - val_loss: 0.0064 - val_mae: 0.0590\n",
      "Epoch 118/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0636 - val_loss: 0.0064 - val_mae: 0.0585\n",
      "Epoch 119/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0624 - val_loss: 0.0063 - val_mae: 0.0582\n",
      "Epoch 120/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0633 - val_loss: 0.0063 - val_mae: 0.0581\n",
      "Epoch 121/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - mae: 0.0673 - val_loss: 0.0062 - val_mae: 0.0582\n",
      "Epoch 122/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0617 - val_loss: 0.0061 - val_mae: 0.0571\n",
      "Epoch 123/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - mae: 0.0629 - val_loss: 0.0061 - val_mae: 0.0571\n",
      "Epoch 124/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0615 - val_loss: 0.0062 - val_mae: 0.0571\n",
      "Epoch 125/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0576 - val_loss: 0.0060 - val_mae: 0.0566\n",
      "Epoch 126/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0638 - val_loss: 0.0060 - val_mae: 0.0567\n",
      "Epoch 127/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - mae: 0.0660 - val_loss: 0.0060 - val_mae: 0.0562\n",
      "Epoch 128/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0582 - val_loss: 0.0060 - val_mae: 0.0559\n",
      "Epoch 129/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0612 - val_loss: 0.0059 - val_mae: 0.0551\n",
      "Epoch 130/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - mae: 0.0602 - val_loss: 0.0058 - val_mae: 0.0546\n",
      "Epoch 131/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0563 - val_loss: 0.0057 - val_mae: 0.0542\n",
      "Epoch 132/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mae: 0.0600 - val_loss: 0.0057 - val_mae: 0.0540\n",
      "Epoch 133/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0586 - val_loss: 0.0058 - val_mae: 0.0546\n",
      "Epoch 134/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mae: 0.0609 - val_loss: 0.0058 - val_mae: 0.0542\n",
      "Epoch 135/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0606 - val_loss: 0.0056 - val_mae: 0.0532\n",
      "Epoch 136/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0595 - val_loss: 0.0057 - val_mae: 0.0534\n",
      "Epoch 137/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0585 - val_loss: 0.0057 - val_mae: 0.0539\n",
      "Epoch 138/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - mae: 0.0583 - val_loss: 0.0056 - val_mae: 0.0533\n",
      "Epoch 139/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0577 - val_loss: 0.0056 - val_mae: 0.0527\n",
      "Epoch 140/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0597 - val_loss: 0.0056 - val_mae: 0.0528\n",
      "Epoch 141/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0575 - val_loss: 0.0055 - val_mae: 0.0524\n",
      "Epoch 142/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0571 - val_loss: 0.0055 - val_mae: 0.0527\n",
      "Epoch 143/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0525 - val_loss: 0.0055 - val_mae: 0.0521\n",
      "Epoch 144/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0555 - val_loss: 0.0054 - val_mae: 0.0520\n",
      "Epoch 145/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0590 - val_loss: 0.0055 - val_mae: 0.0521\n",
      "Epoch 146/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - mae: 0.0541 - val_loss: 0.0054 - val_mae: 0.0514\n",
      "Epoch 147/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0571 - val_loss: 0.0053 - val_mae: 0.0514\n",
      "Epoch 148/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0593 - val_loss: 0.0053 - val_mae: 0.0516\n",
      "Epoch 149/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0054 - val_mae: 0.0514\n",
      "Epoch 150/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0537 - val_loss: 0.0053 - val_mae: 0.0511\n",
      "Epoch 151/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - mae: 0.0543 - val_loss: 0.0052 - val_mae: 0.0505\n",
      "Epoch 152/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0557 - val_loss: 0.0053 - val_mae: 0.0511\n",
      "Epoch 153/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0510\n",
      "Epoch 154/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - mae: 0.0547 - val_loss: 0.0052 - val_mae: 0.0505\n",
      "Epoch 155/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0501\n",
      "Epoch 156/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0528 - val_loss: 0.0052 - val_mae: 0.0505\n",
      "Epoch 157/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0052 - val_mae: 0.0508\n",
      "Epoch 158/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0530 - val_loss: 0.0051 - val_mae: 0.0500\n",
      "Epoch 159/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mae: 0.0555 - val_loss: 0.0051 - val_mae: 0.0499\n",
      "Epoch 160/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - mae: 0.0544 - val_loss: 0.0052 - val_mae: 0.0500\n",
      "Epoch 161/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mae: 0.0539 - val_loss: 0.0051 - val_mae: 0.0497\n",
      "Epoch 162/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0536 - val_loss: 0.0050 - val_mae: 0.0496\n",
      "Epoch 163/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0052 - val_mae: 0.0504\n",
      "Epoch 164/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0493\n",
      "Epoch 165/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mae: 0.0536 - val_loss: 0.0050 - val_mae: 0.0495\n",
      "Epoch 166/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0051 - val_mae: 0.0496\n",
      "Epoch 167/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0580 - val_loss: 0.0050 - val_mae: 0.0492\n",
      "Epoch 168/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - mae: 0.0523 - val_loss: 0.0049 - val_mae: 0.0488\n",
      "Epoch 169/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0528 - val_loss: 0.0049 - val_mae: 0.0490\n",
      "Epoch 170/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mae: 0.0557 - val_loss: 0.0050 - val_mae: 0.0495\n",
      "Epoch 171/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0545 - val_loss: 0.0049 - val_mae: 0.0490\n",
      "Epoch 172/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0568 - val_loss: 0.0049 - val_mae: 0.0488\n",
      "Epoch 173/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0547 - val_loss: 0.0049 - val_mae: 0.0486\n",
      "Epoch 174/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0511 - val_loss: 0.0049 - val_mae: 0.0487\n",
      "Epoch 175/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0049 - val_mae: 0.0490\n",
      "Epoch 176/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0546 - val_loss: 0.0049 - val_mae: 0.0487\n",
      "Epoch 177/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - mae: 0.0543 - val_loss: 0.0049 - val_mae: 0.0487\n",
      "Epoch 178/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0481\n",
      "Epoch 179/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0488\n",
      "Epoch 180/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0488\n",
      "Epoch 181/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - mae: 0.0542 - val_loss: 0.0049 - val_mae: 0.0484\n",
      "Epoch 182/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0048 - val_mae: 0.0478\n",
      "Epoch 183/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0544 - val_loss: 0.0048 - val_mae: 0.0484\n",
      "Epoch 184/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0048 - val_mae: 0.0486\n",
      "Epoch 185/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0048 - val_mae: 0.0480\n",
      "Epoch 186/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0048 - val_mae: 0.0479\n",
      "Epoch 187/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0048 - val_mae: 0.0485\n",
      "Epoch 188/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0534 - val_loss: 0.0048 - val_mae: 0.0483\n",
      "Epoch 189/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0048 - val_mae: 0.0480\n",
      "Epoch 190/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0537 - val_loss: 0.0048 - val_mae: 0.0479\n",
      "Epoch 191/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0530 - val_loss: 0.0047 - val_mae: 0.0473\n",
      "Epoch 192/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mae: 0.0550 - val_loss: 0.0048 - val_mae: 0.0481\n",
      "Epoch 193/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0047 - val_mae: 0.0477\n",
      "Epoch 194/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0513 - val_loss: 0.0047 - val_mae: 0.0476\n",
      "Epoch 195/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0508 - val_loss: 0.0047 - val_mae: 0.0474\n",
      "Epoch 196/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0506 - val_loss: 0.0048 - val_mae: 0.0479\n",
      "Epoch 197/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0519 - val_loss: 0.0048 - val_mae: 0.0482\n",
      "Epoch 198/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0529 - val_loss: 0.0047 - val_mae: 0.0474\n",
      "Epoch 199/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0518 - val_loss: 0.0047 - val_mae: 0.0475\n",
      "Epoch 200/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0047 - val_mae: 0.0471\n",
      "Epoch 201/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0533 - val_loss: 0.0047 - val_mae: 0.0479\n",
      "Epoch 202/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mae: 0.0555 - val_loss: 0.0047 - val_mae: 0.0474\n",
      "Epoch 203/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0502 - val_loss: 0.0047 - val_mae: 0.0472\n",
      "Epoch 204/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0047 - val_mae: 0.0472\n",
      "Epoch 205/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0047 - val_mae: 0.0470\n",
      "Epoch 206/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0539 - val_loss: 0.0047 - val_mae: 0.0476\n",
      "Epoch 207/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0527 - val_loss: 0.0046 - val_mae: 0.0468\n",
      "Epoch 208/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0046 - val_mae: 0.0464\n",
      "Epoch 209/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0047 - val_mae: 0.0480\n",
      "Epoch 210/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0047 - val_mae: 0.0474\n",
      "Epoch 211/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0046 - val_mae: 0.0459\n",
      "Epoch 212/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0047 - val_mae: 0.0472\n",
      "Epoch 213/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 0.0046 - val_mae: 0.0468\n",
      "Epoch 214/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0046 - val_mae: 0.0464\n",
      "Epoch 215/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0046 - val_mae: 0.0470\n",
      "Epoch 216/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - mae: 0.0546 - val_loss: 0.0046 - val_mae: 0.0467\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0562 \n",
      "Test Loss: 0.005213563796132803, Test MAE: 0.05469150096178055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Fit the model with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, epochs=1000, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453220028904801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "[[0.82657427]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'ar' is your input array\n",
    "ar = np.array([0.62765641, 0.42725722, 0.79882862, 1.09386422, 0.61012728,\n",
    "                0.92528814, 0.90911166])\n",
    "\n",
    "# Reshape 'ar' to be a 2D array with shape (1, n_features)\n",
    "ar_reshaped = ar.reshape(1, -1)  # '-1' means to automatically determine the number of columns\n",
    "\n",
    "# Now you can use the model to predict\n",
    "y_tp = model.predict(ar_reshaped)\n",
    "print(y_tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
